# TP : Introduction √† Python et ses biblioth√®ques pour la manipulation de donn√©es

## Objectif

Ce TP a pour but de vous familiariser avec **Python** et les biblioth√®ques fondamentales utilis√©es dans les pipelines de donn√©es. Vous apprendrez √† manipuler des fichiers CSV et JSON, √† utiliser **NumPy** et **Pandas** pour le traitement des donn√©es tabulaires et √† interagir avec **SQLite** via SQLAlchemy.

Nous allons structurer le projet selon une arborescence bien d√©finie pour organiser les fichiers et scripts.

## Arborescence du projet

Voici l'arborescence recommand√©e :

```bash
python-data-pipeline/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ input/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sample.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sample.json
‚îÇ   ‚îú‚îÄ‚îÄ output/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ filtered_data.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transformed.json
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ load_csv.py
‚îÇ   ‚îú‚îÄ‚îÄ manipulate_json.py
‚îÇ   ‚îú‚îÄ‚îÄ pandas_analysis.py
‚îÇ   ‚îú‚îÄ‚îÄ sqlite_interaction.py
‚îÇ   ‚îú‚îÄ‚îÄ scheduler.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ README.md
```

---

## 1. Installation et configuration de l'environnement

Avant de commencer, assurez-vous que **Python 3.8+** est install√© sur votre machine. 

### Installation de l'environnement virtuel

```sh
# Cr√©ation d'un environnement virtuel
python3 -m venv venv

# Activation (Windows)
venv\Scripts\activate

# Activation (Mac/Linux)
source venv/bin/activate
```

### Installation des biblioth√®ques n√©cessaires

```sh
pip install numpy pandas matplotlib seaborn jupyter notebook sqlalchemy sqlite3
```

Ajoutez ces d√©pendances dans `requirements.txt` pour garder une trace des packages install√©s :

```sh
pip freeze > requirements.txt
```
---

## 2. Bases de Python 

### 2.1. Structures de donn√©es

#### Listes
```python
fruits = ["pomme", "banane", "cerise"]
fruits.append("orange")
print(fruits[0])  # pomme
```

#### Dictionnaires
```python
personne = {"nom": "Alice", "age": 25, "ville": "Paris"}
print(personne["nom"])  # Alice
personne["age"] = 26  # Modification
```

#### Boucles et conditions
```python
for fruit in fruits:
    print(fruit)

if "pomme" in fruits:
    print("Il y a une pomme !")
```

#### Fonctions
```python
def carre(x):
    return x * x

print(carre(4))  # 16
```

---

## 3. Manipulation de fichiers CSV et JSON

### 3.1. Lecture et √©criture de fichiers CSV

```python
import csv

# Lecture CSV
with open("data/input/data.csv", newline="") as file:
    reader = csv.reader(file)
    for row in reader:
        print(row)
```

```python
# √âcriture CSV
with open("data/output/output.csv", "w", newline="") as file:
    writer = csv.writer(file)
    writer.writerow(["Nom", "Age"])
    writer.writerow(["Alice", 25])
```

### 3.2. Manipulation de JSON

```python
import json

# Lecture JSON
with open("data/input/data.json", "r") as file:
    data = json.load(file)
    print(data)

# √âcriture JSON
data = {"nom": "Alice", "age": 25}
with open("data/output/output.json", "w") as file:
    json.dump(data, file, indent=4)
```

---

## 4. Manipulation des donn√©es avec Pandas

### 4.1. Chargement et affichage des donn√©es

```python
import pandas as pd

# Charger un CSV
df = pd.read_csv("data/input/data.csv")
print(df.head())
```

### 4.2. S√©lection et filtrage

```python
# S√©lection d'une colonne
print(df["Nom"])

# Filtrage
df_filtre = df[df["Age"] > 25]
print(df_filtre)
```

### 4.3. Manipulation et transformations

```python
# Ajouter une colonne
df["Ann√©e de naissance"] = 2023 - df["Age"]
```

```python
# Supprimer une colonne
df.drop(columns=["Adresse"], inplace=True)
```

### 4.4. Agr√©gation et statistiques

```python
# Statistiques
df.describe()

# Grouper par ville
print(df.groupby("Ville")["Age"].mean())
```

---

## 5. NumPy pour les calculs num√©riques

```python
import numpy as np

arr = np.array([1, 2, 3, 4, 5])
print(arr * 2)
print(np.mean(arr))
```

---

## 6. Introduction √† SQLite et SQLAlchemy

### 6.1. Connexion √† SQLite

```python
from sqlalchemy import create_engine
engine = create_engine("sqlite:///data/database.db")
connection = engine.connect()
```

### 6.2. Cr√©ation d'une table et insertion de donn√©es

```python
connection.execute("""
CREATE TABLE IF NOT EXISTS users (
    id INTEGER PRIMARY KEY,
    name TEXT,
    age INTEGER
)
""")
connection.execute("""
INSERT INTO users (name, age) VALUES ('Alice', 25), ('Bob', 30)
""")
```

### 6.3. Lecture avec Pandas

```python
df = pd.read_sql("SELECT * FROM users", con=engine)
print(df)
```

---

## Exercices

1. **Cr√©er un script Python** qui charge un CSV, filtre les lignes et enregistre le r√©sultat.
2. **Manipuler JSON** : lire et √©crire un fichier JSON.
3. **Utiliser Pandas** pour grouper et analyser un dataset.
4. **Interagir avec SQLite** via SQLAlchemy.

---

---

## Etape 0: Analyse exploratoire des donn√©es

Avant de commencer √† manipuler les donn√©es avec Python et Pandas, il est essentiel de comprendre leur structure et leur contenu. Cette premi√®re √©tape consiste √† charger les datasets et effectuer une analyse exploratoire.

### Objectifs :
- Charger les fichiers de donn√©es (`sales_data.csv`, `customers.csv`, `orders.json`)
- V√©rifier la structure des datasets (types de colonnes, valeurs manquantes, doublons, etc.)
- Analyser les statistiques descriptives
- Visualiser les distributions et les relations entre variables

### 1. Charger les fichiers de donn√©es

Utiliser Pandas pour charger les fichiers et afficher les premi√®res lignes :

```python
import pandas as pd

# Charger les fichiers CSV
df_sales = pd.read_csv("data/sales_data.csv")
df_customers = pd.read_csv("data/customers.csv")

# Charger le fichier JSON
df_orders = pd.read_json("data/orders.json")

# Aper√ßu des donn√©es
print(df_sales.head())
print(df_customers.head())
print(df_orders.head())
```

### 2. V√©rifier la structure des donn√©es

Afficher les types de colonnes et identifier les valeurs manquantes :

```python
# V√©rifier la structure des datasets
print(df_sales.info())
print(df_customers.info())
print(df_orders.info())

# V√©rifier les valeurs manquantes
print(df_sales.isnull().sum())
print(df_customers.isnull().sum())
print(df_orders.isnull().sum())
```

### 3. Analyser les statistiques descriptives

Obtenir des r√©sum√©s statistiques pour les colonnes num√©riques :

```python
# Statistiques descriptives
df_sales.describe()
df_customers.describe()
df_orders.describe()
```

### 4. Visualiser les donn√©es

Cr√©er des graphiques pour explorer les distributions et les relations entre variables :

```python
import matplotlib.pyplot as plt
import seaborn as sns

# Histogramme des montants de ventes
plt.figure(figsize=(10, 5))
sns.histplot(df_sales["total_amount"], bins=30, kde=True)
plt.title("Distribution des montants de ventes")
plt.show()

# R√©partition des commandes par pays
plt.figure(figsize=(12, 5))
df_customers["country"].value_counts().plot(kind="bar")
plt.title("Nombre de clients par pays")
plt.xticks(rotation=45)
plt.show()
```
---

Cette premi√®re partie est essentielle pour comprendre les bases avant d'aborder la **construction de pipelines de donn√©es** dans la suite du TP.

## 1. Chargement et manipulation de fichiers CSV

### Objectif :
Charger un fichier CSV, appliquer des filtres et sauvegarder un nouveau fichier transform√©.

### Fichier : `scripts/load_csv.py`

### Exercices pratiques :

1. **Charger un fichier CSV en DataFrame avec Pandas.**
   ```python
   import pandas as pd
   df = pd.read_csv("data/sales_data.csv")
   print(df.head())
   ```

2. **Filtrer les lignes selon une condition donn√©e (ex: garder uniquement les valeurs sup√©rieures √† 500 dans une colonne `total_amount`).**
   ```python
   df_filtered = df[df['total_amount'] > 500]
   print(df_filtered.head())
   ```

3. **Remplacer les valeurs manquantes d‚Äôune colonne par la moyenne des valeurs existantes.**
   ```python
   df['total_amount'].fillna(df['total_amount'].mean(), inplace=True)
   ```

4. **Renommer certaines colonnes du fichier CSV.**
   ```python
   df.rename(columns={'old_column': 'new_column'}, inplace=True)
   ```

5. **Trier le DataFrame par plusieurs colonnes.**
   ```python
   df_sorted = df.sort_values(by=['customer_id', 'total_amount'], ascending=[True, False])
   ```

6. **Sauvegarder le DataFrame filtr√© dans un fichier `filtered_data.csv`.**
   ```python
   df_filtered.to_csv("data/output/filtered_data.csv", index=False)
   ```

---

## 2. Lecture et manipulation de fichiers JSON

### Objectif :
Lire un fichier JSON, modifier son contenu, et sauvegarder un fichier transform√©.

### Fichier : `scripts/manipulate_json.py`

### Exercices pratiques :

1. **Charger un fichier JSON en Python.**
   ```python
   import json
   with open("data/customers.json") as f:
       data = json.load(f)
   ```

2. **Modifier une cl√© sp√©cifique d‚Äôun dictionnaire JSON.**
   ```python
   data["customer_name"] = "John Doe"
   ```

3. **Ajouter un nouvel √©l√©ment √† un fichier JSON.**
   ```python
   data["new_key"] = "new_value"
   ```

4. **Supprimer une cl√© sp√©cifique du fichier JSON.**
   ```python
   del data["old_key"]
   ```

5. **Convertir un fichier JSON en DataFrame Pandas.**
   ```python
   import pandas as pd
   df = pd.DataFrame.from_dict(data)
   ```

6. **Sauvegarder les modifications dans un fichier `transformed.json`.**
   ```python
   with open("data/output/transformed.json", "w") as f:
       json.dump(data, f, indent=4)
   ```

---

## 3. Analyse de donn√©es avec Pandas

### Objectif :
Charger un dataset et r√©aliser des statistiques descriptives.

### Fichier : `scripts/pandas_analysis.py`

### Exercices pratiques :

1. **Charger un dataset et afficher ses informations g√©n√©rales.**
   ```python
   df.info()
   df.describe()
   ```

2. **Grouper les donn√©es par une colonne et calculer la moyenne d‚Äôune autre colonne.**
   ```python
   df_grouped = df.groupby('customer_id')['total_amount'].mean()
   ```

3. **Filtrer un DataFrame pour afficher uniquement certaines valeurs.**
   ```python
   df_filtered = df[df['country'] == 'France']
   ```

4. **Fusionner deux DataFrames en utilisant une cl√© commune.**
   ```python
   df_merged = pd.merge(df_customers, df_sales, on='customer_id')
   ```

5. **Cr√©er une nouvelle colonne calcul√©e √† partir d‚Äôautres colonnes.**
   ```python
   df['total_with_tax'] = df['total_amount'] * 1.2
   ```

6. **G√©n√©rer un histogramme d‚Äôune colonne sp√©cifique.**
   ```python
   import matplotlib.pyplot as plt
   df['total_amount'].hist()
   plt.show()
   ```

---

## 4. Interagir avec SQLite via SQLAlchemy

### Objectif :
Cr√©er une base de donn√©es SQLite, ins√©rer des donn√©es et les manipuler avec SQLAlchemy.

### Fichier : `scripts/sqlite_interaction.py`

### Exercices pratiques :

1. **Cr√©er une base de donn√©es SQLite et une table avec SQLAlchemy.**
   ```python
   from sqlalchemy import create_engine, Column, Integer, String, Float, MetaData, Table
   engine = create_engine("sqlite:///data/database.db")
   metadata = MetaData()
   customers = Table('customers', metadata,
       Column('id', Integer, primary_key=True),
       Column('name', String),
       Column('total_spent', Float)
   )
   metadata.create_all(engine)
   ```

2. **Ins√©rer plusieurs lignes de donn√©es dans une table.**
   ```python
   from sqlalchemy.orm import sessionmaker
   Session = sessionmaker(bind=engine)
   session = Session()
   session.execute(customers.insert().values(id=1, name="Alice", total_spent=200.0))
   session.commit()
   ```

3. **Ex√©cuter une requ√™te SELECT pour r√©cup√©rer toutes les donn√©es d‚Äôune table.**
   ```python
   result = session.execute(customers.select()).fetchall()
   for row in result:
       print(row)
   ```

4. **Filtrer les r√©sultats d‚Äôune requ√™te SQLAlchemy.**
   ```python
   result = session.execute(customers.select().where(customers.c.total_spent > 100)).fetchall()
   ```

5. **Mettre √† jour une entr√©e sp√©cifique dans la base de donn√©es.**
   ```python
   session.execute(customers.update().where(customers.c.id == 1).values(total_spent=300.0))
   session.commit()
   ```

6. **Convertir le r√©sultat d‚Äôune requ√™te SQL en DataFrame Pandas.**
   ```python
   import pandas as pd
   df = pd.read_sql("SELECT * FROM customers", engine)
   ```

   ---

## 3. Cr√©ation de pipelines de donn√©es (ETL)

### Objectif :
Cr√©er une premi√®re pipeline ETL permettant d‚Äôextraire, transformer et charger des donn√©es en automatisant les t√¢ches. Ci-apr√®s figurent des indications et des pistes avec des extraits de code. Cependant, c'est √† vous de bien stucturer les √©tapes de cette premi√®re pipeline en utilisant les bonnes pratiques vues durant le cours (fonctions r√©utilisables, logs, documentation des fonctions, utiliser les bons scripts python pour la bonne action,...)

### Structure du pipeline :
Le pipeline sera structur√© en trois √©tapes principales :
1. **Extraction** : Charger des fichiers CSV et JSON en DataFrame.
2. **Transformation** : Nettoyage et enrichissement des donn√©es.
3. **Chargement** : Sauvegarde des donn√©es dans une base SQLite.

### Fichier : `scripts/etl_pipeline.py`

### √âtapes de la pipeline :

#### 1. Extraction des donn√©es

```python
import pandas as pd
import json

def extract_csv(file_path):
    return pd.read_csv(file_path)

def extract_json(file_path):
    with open(file_path, "r") as f:
        return pd.DataFrame(json.load(f))

sales_data = extract_csv("data/sales_data.csv")
customers_data = extract_json("data/customers.json")
```

#### 2. Transformation des donn√©es

```python
# Nettoyage des donn√©es
sales_data.dropna(inplace=True)
sales_data = sales_data[sales_data['total_amount'] > 0]

# Fusion avec les donn√©es clients
merged_data = pd.merge(sales_data, customers_data, on='customer_id', how='left')

# Cr√©ation d‚Äôune nouvelle colonne
merged_data['total_with_tax'] = merged_data['total_amount'] * 1.2
```

#### 3. Chargement des donn√©es dans SQLite

```python
from sqlalchemy import create_engine

engine = create_engine("sqlite:///data/database.db")
merged_data.to_sql("sales_data", con=engine, if_exists="replace", index=False)
```

#### 4. Planification de l'ex√©cution (Scheduling)

Un pipeline ETL peut √™tre automatis√© √† l'aide de `cron` sous Linux ou d'un planificateur de t√¢ches sous Windows.

**Exemple de configuration avec `cron` :**

Ouvrir le crontab avec la commande :
```bash
crontab -e
```

Ajouter une ligne pour ex√©cuter le script tous les jours √† minuit :
```bash
0 0 * * * /usr/bin/python3 /chemin/vers/le_projet/scripts/etl_pipeline.py
```

**Sur Windows, utiliser le planificateur de t√¢ches :**
- Cr√©er une nouvelle t√¢che
- S√©lectionner "Ex√©cuter un programme"
- Ajouter `python.exe` comme programme et `C:\chemin\vers\le_projet\scripts\etl_pipeline.py` comme argument.

---

### Conclusion
Cette premi√®re pipeline de donn√©es permet d‚Äôacqu√©rir les bases de la manipulation et de l‚Äôautomatisation des traitements de donn√©es. Elle sera la base des prochaines √©tapes, o√π nous int√©grerons des outils avanc√©s comme **Apache Airflow** ou **Dagster** pour orchestrer et surveiller les pipelines de donn√©es de mani√®re plus robuste.

üìå **Prochaine √©tape :** Am√©liorer la pipeline en ajoutant des logs et la gestion des erreurs pour rendre l‚Äôautomatisation plus fiable.

