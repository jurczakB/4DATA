# Aper√ßu du Projet

Dans ce cours, nous allons nous concentrer sur les orchestrateurs ax√©s sur les assets et sur la mani√®re dont ils simplifient la gestion des pipelines de donn√©es. Vous allez utiliser **Dagster**, un orchestrateur open-source, pour construire un pipeline de donn√©es exemple.

√Ä l'aide des donn√©es issues de **NYC OpenData**, vous allez cr√©er un pipeline de donn√©es qui :

- **Extrait** les donn√©es stock√©es dans des fichiers Parquet depuis NYC OpenData.
- **Charge** ces donn√©es dans une base de donn√©es **DuckDB**.
- **Transforme** et pr√©pare les donn√©es pour l'analyse.
- **Cr√©e une visualisation** √† partir des donn√©es transform√©es.

Si vous √™tes bloqu√© ou souhaitez avancer plus rapidement, consultez le projet finalis√© disponible sur **GitHub**.

---

## Pr√©requis

Pour installer **Dagster**, vous aurez besoin de :

- **Installer Python**. Dagster prend en charge **Python 3.9 √† 3.12**.
- Un **gestionnaire de paquets** comme **pip**, **Poetry** ou **uv**. Si vous devez installer un gestionnaire de paquets, consultez les guides d'installation suivants :
  - [pip](https://pip.pypa.io/en/stable/installation/)
  - [Poetry](https://python-poetry.org/docs/#installation)
  - [uv](https://github.com/astral-sh/uv)

Pour v√©rifier si **Python** et le **gestionnaire de paquets** sont d√©j√† install√©s dans votre environnement, ex√©cutez :

```sh
python --version
pip --version
```

---

## Installation

üí° **Remarque** : Nous recommandons fortement d'installer Dagster dans un **environnement virtuel Python**. Si vous avez besoin d'un rappel sur la cr√©ation et l'activation d'un environnement virtuel, consultez [cet article de blog](https://realpython.com/python-virtual-environments-a-primer/).

Pour installer **Dagster** dans votre environnement Python actuel, ex√©cutez la commande suivante :

```sh
pip install dagster~=1.9
```

---

## Cr√©ation du projet Dagster

Cr√©ons votre premier projet Dagster ! Pour cela, utilisez la commande `dagster project from-example` afin de cloner le projet officiel **Dagster University** sur votre machine locale.

Pour cr√©er le projet, ex√©cutez :

```sh
dagster project from-example --example project_dagster_university_start --name dagster_university
```

Apr√®s l'ex√©cution de cette commande, un nouveau r√©pertoire nomm√© **dagster_university** sera cr√©√© dans votre r√©pertoire actuel. Ce r√©pertoire contiendra les fichiers constituant votre projet Dagster.

Ensuite, configurez les variables d'environnement par d√©faut et installez les d√©pendances Python du projet en ex√©cutant :

```sh
cd dagster_university
cp .env.example .env
pip install -e ".[dev]"
```

L'option `-e` installe le projet en mode **√©ditable**, ce qui am√©liore l'exp√©rience de d√©veloppement en r√©duisant le temps n√©cessaire pour tester une modification. Les principales exceptions sont l'ajout de nouveaux assets ou l'installation de d√©pendances suppl√©mentaires.

Pour v√©rifier que l'installation a r√©ussi et que vous pouvez ex√©cuter Dagster en local, lancez :

```sh
dagster dev
```

Naviguez vers **[localhost:3000](http://localhost:3000)**, o√π vous devriez voir l'interface utilisateur de Dagster.

üí° **Remarque** : La commande `dagster dev` ex√©cutera Dagster en continu jusqu'√† ce que vous l'arr√™tiez. Pour arr√™ter le processus en cours d'ex√©cution, utilisez **Control + C** dans le terminal.

---

## D√©finition de votre premier asset

Dans ce cours, vous utiliserez les donn√©es de **NYC OpenData** pour analyser les trajets en taxi √† New York. Le premier asset que vous allez d√©finir utilise les donn√©es de **TLC Trip Record Data**, qui contient les enregistrements de trajets pour plusieurs types de v√©hicules. Nous nous concentrerons sur les taxis jaunes.

Votre premier asset, nomm√© `taxi_trips_file`, va r√©cup√©rer les donn√©es des taxis jaunes pour **mars 2023** et les enregistrer localement.

1. **Ouvrir le fichier `assets/trips.py`** dans votre projet Dagster.
2. **V√©rifier que les imports suivants existent d√©j√†** en haut du fichier :

```python
import requests
from . import constants
```

3. **D√©finir une fonction qui r√©cup√®re les donn√©es et les sauvegarde localement** :

```python
def taxi_trips_file() -> None:
    """
    R√©cup√®re les fichiers Parquet bruts des trajets en taxi.
    Sourced from the NYC Open Data portal.
    """
    month_to_fetch = '2023-03'
    raw_trips = requests.get(
        f"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{month_to_fetch}.parquet"
    )

    with open(constants.TAXI_TRIPS_TEMPLATE_FILE_PATH.format(month_to_fetch), "wb") as output_file:
        output_file.write(raw_trips.content)
```

4. **Transformer cette fonction en un asset Dagster** :

    - **Importer `asset` depuis la biblioth√®que Dagster** :

    ```python
    from dagster import asset
    ```

    - **Ajouter le d√©corateur `@asset` avant la fonction** :

    ```python
    @asset
    def taxi_trips_file() -> None:
        """
        R√©cup√®re les fichiers Parquet bruts des trajets en taxi.
        """
        month_to_fetch = '2023-03'
        raw_trips = requests.get(
            f"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{month_to_fetch}.parquet"
        )

        with open(constants.TAXI_TRIPS_TEMPLATE_FILE_PATH.format(month_to_fetch), "wb") as output_file:
            output_file.write(raw_trips.content)
    ```

C'est tout ! üéâ Vous venez de cr√©er votre premier **asset Dagster**. En utilisant le d√©corateur `@asset`, vous pouvez facilement transformer une fonction Python en un asset Dagster.

‚ÑπÔ∏è **Note sur `-> None`** : Il s'agit d'une **annotation de type** en Python indiquant que la fonction ne retourne rien. L'utilisation des annotations de type est fortement recommand√©e pour rendre le code plus lisible et compr√©hensible.


---

## Mat√©rialisation de votre asset

Une fois votre asset d√©fini dans le code, l'√©tape suivante consiste √† le **mat√©rialiser**. Lorsqu'un asset est mat√©rialis√©, Dagster ex√©cute la fonction associ√©e et enregistre le r√©sultat dans un stockage, comme un entrep√¥t de donn√©es.

### Ex√©cution de la mat√©rialisation via l'interface Dagster

Si vous n'avez pas encore l'interface **Dagster UI** en cours d'ex√©cution, d√©marrez-la en ex√©cutant la commande suivante √† la racine de votre projet Dagster :

```sh
dagster dev
```

Puis, acc√©dez √† **[localhost:3000](http://localhost:3000)** dans votre navigateur.

1. **Cliquez sur "Assets" dans la barre de navigation sup√©rieure**. Vous verrez la liste des assets disponibles dans le projet.
2. **Si la page est vide, cliquez sur "Reload definitions"** pour recharger les d√©finitions des assets.
3. **Cliquez sur "View global asset lineage"** pour visualiser la hi√©rarchie de votre asset.
4. **Cliquez sur le bouton "Materialize"** pour ex√©cuter la fonction de l'asset et g√©n√©rer le fichier de donn√©es.
5. **Une bo√Æte de notification violette appara√Ætra**, indiquant que l'ex√©cution a d√©marr√© avec succ√®s.
6. **Une fois la mat√©rialisation termin√©e**, acc√©dez au r√©pertoire `data/raw/` dans votre projet et v√©rifiez la pr√©sence du fichier g√©n√©r√© :

```sh
ls data/raw/taxi_trips_2023-03.parquet
```

üí° **Remarque** : Le t√©l√©chargement du fichier peut prendre quelques instants.

C'est tout ! üéâ Vous avez maintenant **mat√©rialis√© votre premier asset** avec Dagster !

---

## Consultation des d√©tails d'ex√©cution

Maintenant que vous avez mat√©rialis√© un asset, il est essentiel de savoir comment consulter les d√©tails d'ex√©cution.

1. **Localiser l'ex√©cution de la mat√©rialisation**
   - Dans l'interface **Dagster UI**, rep√©rez la section **Materialized - <DATE>** sur la page de l'asset.
   - Cliquez sur la **date** mise en √©vidence pour acc√©der √† la page de d√©tails d'ex√©cution.

2. **Consulter les logs et informations**
   - La page affichera des informations sur l'ex√©cution, y compris les **logs**, les **statuts d'ex√©cution**, et les √©ventuelles **erreurs**.
   - Vous pouvez utiliser ces d√©tails pour **identifier et r√©soudre d'√©ventuels probl√®mes**.

Si votre ex√©cution avait √©chou√©, cette page vous aiderait √† diagnostiquer la cause et √† ajuster votre code en cons√©quence. Parcourez la afin de vous familiariser avec l'UI et un potentiel d√©buggage...

---

## D√©pannage des ex√©cutions √©chou√©es

Si un asset √©choue lors de sa mat√©rialisation, vous pouvez identifier la cause et corriger l'erreur en suivant ces √©tapes :

1. **D√©clencher une erreur intentionnelle**
   - Modifiez `assets/trips.py` en commentant l'importation de `constants`.
   - Lancez la mat√©rialisation dans **Dagster UI** et observez l'√©chec.

2. **Analyser les logs d'ex√©cution**
   - Ouvrez les **Run details** et rep√©rez le statut **Failure**.
   - Identifiez l'√©tape en √©chec via le message d'erreur dans les logs.

3. **Corriger l'erreur**
   - R√©activez l'importation de `constants` dans `trips.py` et enregistrez.
   - Fermez la fen√™tre d'erreur dans **Dagster UI**.

4. **Relancer l'ex√©cution**
   - Cliquez sur **Re-execute all** dans **Dagster UI** pour relancer toutes les √©tapes.
   - V√©rifiez que la mat√©rialisation aboutit avec succ√®s.

Ces √©tapes vous permettront de comprendre comment utiliser les logs et les outils de Dagster pour diagnostiquer et corriger les erreurs efficacement.

---

## Cr√©ation d'un asset taxi_zones_file

Pour mettre en pratique ce que vous avez appris, cr√©ez un nouvel asset dans `trips.py` qui :

- **Est nomm√© `taxi_zones_file`**, qui contiendra un identifiant unique et le nom de chaque zone de taxi √† New York.
- **Utilise la biblioth√®que `requests`** pour r√©cup√©rer les donn√©es depuis l'URL suivante :
  
  `https://community-engineering-artifacts.s3.us-west-2.amazonaws.com/dagster-university/data/taxi_zones.csv`
  
- **Stocke les donn√©es sous forme de fichier CSV** dans `data/raw/taxi_zones.csv`. Le chemin est d√©fini dans `constants.TAXI_ZONES_FILE_PATH`.

Une fois cet asset cr√©√© et ajout√© √† votre projet, vous pourrez le mat√©rialiser de la m√™me mani√®re que l'asset pr√©c√©dent en utilisant l'interface **Dagster UI**.

---

## Cr√©ation d'un pipeline de donn√©es

Jusqu'ici, nous avons vu ce qu'est un asset et comment en cr√©er dans Dagster. Maintenant, nous allons √©tendre votre projet Dagster pour construire un pipeline de donn√©es.

Les pipelines de donn√©es sont une suite d'√©v√©nements produisant des assets. Dagster permet de cr√©er efficacement ces pipelines tout en g√©rant plusieurs assets interd√©pendants.

Vous allez maintenant construire un pipeline complet qui :

- **Charge les fichiers t√©l√©charg√©s dans une base de donn√©es**.
- **Combine et agr√®ge les donn√©es** pour g√©n√©rer des m√©triques sur les trajets en taxi.
- **Visualise ces m√©triques et enregistre un rapport**.

Pendant ce processus, vous apprendrez √† d√©finir des d√©pendances entre assets pour structurer vos pipelines efficacement.

---

## Ex√©cution des assets et base de donn√©es

Pr√©c√©demment, nous avons cr√©√© deux assets ind√©pendants : `taxi_trips_file` et `taxi_zones_file`. Maintenant, nous allons cr√©er de nouveaux assets qui d√©pendent de ces fichiers de donn√©es.

Avant de travailler avec ces fichiers, il est pr√©f√©rable de les charger dans une base de donn√©es pour am√©liorer l'efficacit√© et le stockage. Heureusement, le projet est configur√© avec **DuckDB**, une base de donn√©es int√©gr√©e qui facilite l'ingestion et la requ√™te de donn√©es.

DuckDB permet notamment d'ex√©cuter des requ√™tes SQL directement sur des fichiers. Par exemple, pour charger le fichier `taxi_trips_file` dans DuckDB, on pourrait ex√©cuter la requ√™te SQL suivante :

```sql
CREATE OR REPLACE TABLE trips AS (
    SELECT
        VendorID AS vendor_id,
        PULocationID AS pickup_zone_id,
        DOLocationID AS dropoff_zone_id,
        RatecodeID AS rate_code_id,
        payment_type AS payment_type,
        tpep_dropoff_datetime AS dropoff_datetime,
        tpep_pickup_datetime AS pickup_datetime,
        trip_distance AS trip_distance,
        passenger_count AS passenger_count,
        total_amount AS total_amount
    FROM 'data/raw/taxi_trips_2023-03.parquet'
);
```

Nous verrons dans la prochaine section comment ex√©cuter cette requ√™te et int√©grer ce chargement dans Dagster.

---

## Chargement des donn√©es dans la base de donn√©es

Maintenant que nous avons d√©fini une requ√™te SQL permettant de charger les donn√©es dans **DuckDB**, nous allons utiliser **Dagster** pour g√©rer la mat√©rialisation de ces assets. En d√©l√©guant cette t√¢che √† Dagster, nous pouvons facilement suivre l'√©volution des tables et mesurer le temps d'ex√©cution.

### D√©finition de l'asset `taxi_trips`

Ajoutez le code suivant √† la fin du fichier `trips.py` :

```python
import duckdb
import os
from dagster import asset
from dagster._utils.backoff import backoff

@asset(
    deps=["taxi_trips_file"]
)
def taxi_trips() -> None:
    """
    Le jeu de donn√©es brut des trajets en taxi, charg√© dans une base de donn√©es DuckDB.
    """
    query = """
        CREATE OR REPLACE TABLE trips AS (
          SELECT
            VendorID AS vendor_id,
            PULocationID AS pickup_zone_id,
            DOLocationID AS dropoff_zone_id,
            RatecodeID AS rate_code_id,
            payment_type AS payment_type,
            tpep_dropoff_datetime AS dropoff_datetime,
            tpep_pickup_datetime AS pickup_datetime,
            trip_distance AS trip_distance,
            passenger_count AS passenger_count,
            total_amount AS total_amount
          FROM 'data/raw/taxi_trips_2023-03.parquet'
        );
    """

    conn = backoff(
        fn=duckdb.connect,
        retry_on=(RuntimeError, duckdb.IOException),
        kwargs={
            "database": os.getenv("DUCKDB_DATABASE"),
        },
        max_retries=10,
    )
    conn.execute(query)
```

### Explication du code

- **Le d√©corateur `@asset`** : Permet √† Dagster de reconna√Ætre `taxi_trips` comme un asset.
- **D√©pendance `deps=["taxi_trips_file"]`** : Assure que `taxi_trips_file` est mat√©rialis√© avant `taxi_trips`.
- **Requ√™te SQL** : Cr√©e ou remplace la table `trips` en important les donn√©es du fichier `taxi_trips_file`.
- **Connexion s√©curis√©e avec `backoff`** : Permet d'√©viter des conflits d'acc√®s multiples √† DuckDB.

### Rechargement des d√©finitions

Apr√®s avoir ajout√© ce nouvel asset, vous devez **recharger les d√©finitions** dans **Dagster UI** :

1. Ouvrez **Dagster UI**.
2. Cliquez sur **"Reload Definitions"**.
3. V√©rifiez que `taxi_trips` appara√Æt dans le graphe des assets avec une fl√®che indiquant sa d√©pendance √† `taxi_trips_file`.

### Mat√©rialisation du pipeline

Dans **Dagster UI**, cliquez sur **"Materialize all"** pour lancer l'ex√©cution des assets :

- **`taxi_trips_file` et `taxi_zones_file` sont ex√©cut√©s en parall√®le**.
- **`taxi_trips` attend que `taxi_trips_file` soit compl√©t√©** avant d'√™tre mat√©rialis√©.

Cela est possible gr√¢ce √† la d√©claration de d√©pendance `deps=["taxi_trips_file"]`.

### V√©rification de la mat√©rialisation

Pour confirmer que les donn√©es ont bien √©t√© charg√©es dans DuckDB, ouvrez un terminal et ex√©cutez les commandes suivantes :

```python
import duckdb
conn = duckdb.connect(database="data/staging/data.duckdb")
conn.execute("SELECT COUNT(*) FROM trips").fetchall()
```

Si tout s'est bien pass√©, cette commande affichera le nombre de trajets de taxi ing√©r√©s.

üöÄ **F√©licitations !** Vous avez maintenant construit un pipeline de donn√©es complet qui r√©cup√®re des donn√©es depuis une API et les stocke dans une base de donn√©es pour analyse.

---  

### Pratique : Cr√©ation d'un asset `taxi_zones`

En utilisant vos connaissances sur la gestion des d√©pendances entre assets, cr√©ez un asset `taxi_zones` qui utilise `taxi_zones_file` pour g√©n√©rer une table `zones` dans DuckDB.

Cet asset doit :

- **S'appeler `taxi_zones`**.
- **Utiliser le fichier `taxi_zones_file`** comme source de donn√©es.
- **Cr√©er une table `zones` dans DuckDB** avec les colonnes suivantes :
  - `zone_id`, correspondant √† `LocationID`, renomm√©.
  - `zone`.
  - `borough`.
  - `geometry`, correspondant √† `the_geom`, renomm√©.

### Instructions

1. Modifiez le fichier `trips.py` pour ajouter l'asset `taxi_zones`.
2. Assurez-vous que `taxi_zones_file` est correctement r√©f√©renc√© comme d√©pendance.
3. Utilisez une requ√™te SQL pour transformer et charger les donn√©es dans DuckDB.
4. Rechargez les d√©finitions dans **Dagster UI**.
5. Mat√©rialisez l'asset `taxi_zones` apr√®s `taxi_zones_file`.
6. V√©rifiez que la table `zones` a bien √©t√© cr√©√©e dans DuckDB.

üí° **Astuce** : Utilisez Dagster UI pour suivre les d√©pendances et vous assurer que la mat√©rialisation s'ex√©cute correctement.

---

### Assets avec calculs en m√©moire

Jusqu'√† pr√©sent, nous avons orchestr√© des calculs dans une base de donn√©es et effectu√© des t√¢ches l√©g√®res en Python, comme le t√©l√©chargement de fichiers. Dans cette section, vous allez utiliser Dagster pour orchestrer des calculs en Python et g√©n√©rer un rapport.

#### Introduction aux assets avec calculs en m√©moire

Jusqu'ici, les assets d√©finis impliquaient soit l'ex√©cution de requ√™tes SQL dans une base de donn√©es, soit des op√©rations l√©g√®res comme le t√©l√©chargement de fichiers. Maintenant, vous allez apprendre √† utiliser **Dagster** pour orchestrer des calculs en **Python pur**, afin de transformer vos donn√©es et g√©n√©rer des rapports.

Afin de mieux organiser le projet, nous allons **s√©parer les assets selon leur fonction** : les assets li√©s √† l'analyse seront plac√©s dans un fichier distinct.

1. **Cr√©ez et ouvrez `metrics.py` dans le r√©pertoire `assets/`**.
2. **Ajoutez les imports suivants au d√©but du fichier :**

```python
from dagster import asset
import matplotlib.pyplot as plt
import geopandas as gpd
import duckdb
import os
from . import constants
```

3. **D√©finissez un nouvel asset `manhattan_stats` et ses d√©pendances :**

```python
@asset(
    deps=["taxi_trips", "taxi_zones"]
)
def manhattan_stats() -> None:
    """
    Calcule les statistiques des trajets en taxi pour Manhattan et les stocke au format GeoJSON.
    """
    query = """
        SELECT
            zones.zone,
            zones.borough,
            zones.geometry,
            COUNT(1) AS num_trips
        FROM trips
        LEFT JOIN zones ON trips.pickup_zone_id = zones.zone_id
        WHERE borough = 'Manhattan' AND geometry IS NOT NULL
        GROUP BY zone, borough, geometry
    """

    conn = duckdb.connect(os.getenv("DUCKDB_DATABASE"))
    trips_by_zone = conn.execute(query).fetch_df()

    trips_by_zone["geometry"] = gpd.GeoSeries.from_wkt(trips_by_zone["geometry"])
    trips_by_zone = gpd.GeoDataFrame(trips_by_zone)

    with open(constants.MANHATTAN_STATS_FILE_PATH, 'w') as output_file:
        output_file.write(trips_by_zone.to_json())
```

4. **Recharger les d√©finitions dans Dagster UI et mat√©rialiser `manhattan_stats`**.
5. **V√©rifiez la cr√©ation du fichier JSON dans `data/staging/manhattan_stats.geojson`**.

### Cr√©ation d'une carte

Cr√©ez un asset `manhattan_map` qui d√©pend de `manhattan_stats`, charge ses donn√©es GeoJSON et g√©n√®re une visualisation.

1. **Ajoutez le code suivant √† la fin du fichier `metrics.py` :**

```python
@asset(
    deps=["manhattan_stats"]
)
def manhattan_map() -> None:
    """
    G√©n√®re une carte des trajets en taxi √† Manhattan et l'enregistre sous forme d'image.
    """
    trips_by_zone = gpd.read_file(constants.MANHATTAN_STATS_FILE_PATH)

    fig, ax = plt.subplots(figsize=(10, 10))
    trips_by_zone.plot(column="num_trips", cmap="plasma", legend=True, ax=ax, edgecolor="black")
    ax.set_title("Nombre de trajets par zone de taxi √† Manhattan")

    ax.set_xlim([-74.05, -73.90])
    ax.set_ylim([40.70, 40.82])
    
    plt.savefig(constants.MANHATTAN_MAP_FILE_PATH, format="png", bbox_inches="tight")
    plt.close(fig)
```

2. **Rechargez les d√©finitions dans Dagster UI**.
3. **Mat√©rialisez `manhattan_map`**.
4. **V√©rifiez la cr√©ation de l'image `manhattan_map.png` dans `data/outputs/`**.

### Explication du code

- **L'asset `manhattan_map` d√©pend de `manhattan_stats`** et charge ses donn√©es GeoJSON.
- **Utilise Matplotlib pour g√©n√©rer une visualisation** de la r√©partition des trajets en taxi.
- **Stocke l'image g√©n√©r√©e sous `data/outputs/manhattan_map.png`**.

üöÄ **F√©licitations !** Vous avez orchestr√© un calcul en m√©moire et g√©n√©r√© une visualisation de donn√©es avec Dagster.

---  

### Exercice : Cr√©ation d'un asset `trips_by_week`

Pour mettre en pratique ce que vous avez appris, cr√©ez un asset dans `metrics.py` qui :

- **S'appelle `trips_by_week`**.
- **Produit un fichier CSV** qui :
  - Est enregistr√© √† l'emplacement d√©fini par `constants.TRIPS_BY_WEEK_FILE_PATH`.
  - Contient les colonnes suivantes :
    - `period` : une cha√Æne de caract√®res repr√©sentant le dimanche de la semaine agr√©g√©e (ex. `2023-03-05`).
    - `num_trips` : le nombre total de trajets commenc√©s durant cette semaine.
    - `passenger_count` : le nombre total de passagers sur les trajets de cette semaine.
    - `total_amount` : la somme totale des revenus g√©n√©r√©s par les trajets de cette semaine.
    - `trip_distance` : la distance totale parcourue en miles pour tous les trajets de cette semaine.

### Contraintes suppl√©mentaires (optionnel - challenge avanc√©)

Si vous souhaitez aller plus loin, imaginez que l'ensemble des donn√©es des trajets est trop volumineux pour √™tre charg√© enti√®rement en m√©moire, mais qu'une semaine de donn√©es peut √™tre trait√©e confortablement. R√©fl√©chissez √† une approche permettant d'adapter l'impl√©mentation en cons√©quence.

### Conseils

- Toutes les notions n√©cessaires ont d√©j√† √©t√© abord√©es.
- Il existe plusieurs solutions possibles, soit en manipulant la base de donn√©es, soit en agr√©geant un `DataFrame`.
- Aucun import suppl√©mentaire n'est n√©cessaire, mais vous pouvez importer tout ce dont vous avez besoin.
- Pour √©viter les probl√®mes li√©s √† la qualit√© des donn√©es, vous pouvez fixer la p√©riode d'analyse entre des dates connues (ex. `2023-03-01` √† `2023-03-31`).
- La fonction `date_trunc` de **DuckDB** permet de tronquer une date √† la pr√©cision `week`.
- DuckDB permet d'ajouter des intervalles de temps avec `+ INTERVAL '1 week'`.

### Exemple de sortie attendue

Le fichier CSV g√©n√©r√© pourrait ressembler √† ceci :

```
period,num_trips,total_amount,trip_distance,passenger_count
2023-03-05,679681,18495110.72,2358944.42,886486
2023-03-12,686461,19151177.45,2664123.87,905296
2023-03-19,640158,17908993.09,2330611.91,838066
```

üöÄ **√Ä vous de jouer !** Impl√©mentez cet asset et v√©rifiez son bon fonctionnement en le mat√©rialisant via **Dagster UI**.

---

### Comprendre l'objet `Definitions`

L'objet **`Definitions`** regroupe l'ensemble des d√©finitions utilis√©es par Dagster et les rend accessibles aux outils Dagster. Il permet d'assigner des d√©finitions √† une **code location**, chaque code location ne pouvant contenir qu'un seul `Definitions`. Cela permet d'isoler plusieurs projets Dagster sans n√©cessiter plusieurs d√©ploiements.

#### O√π est d√©fini `Definitions` ?

Dans Dagster, l'objet `Definitions` est d√©fini dans le fichier `__init__.py` √† la racine du projet. Ce fichier joue un r√¥le cl√© dans la gestion des assets et leur d√©couverte par Dagster.

Ouvrez le fichier `dagster_university/__init__.py` dans votre projet. Il devrait contenir un code similaire √† ceci :

```python
from dagster import Definitions, load_assets_from_modules

from .assets import trips, metrics

trip_assets = load_assets_from_modules([trips])
metric_assets = load_assets_from_modules([metrics])

defs = Definitions(
    assets=[*trip_assets, *metric_assets]
)
```

### D√©composition du fichier `__init__.py`

1. **Importation des outils Dagster**

```python
from dagster import Definitions, load_assets_from_modules
```

Cette ligne introduit l'objet `Definitions` et la m√©thode `load_assets_from_modules`, utilis√©e pour charger les assets d√©finis dans le projet.

2. **Organisation des assets en modules**

```python
from .assets import trips, metrics
```

Conform√©ment aux bonnes pratiques recommand√©es par Dagster, les assets sont stock√©s dans des modules distincts.

3. **Chargement des assets √† partir des modules**

```python
trip_assets = load_assets_from_modules([trips])
metric_assets = load_assets_from_modules([metrics])
```

Cette √©tape stocke les assets des modules `trips` et `metrics` dans des variables, en les chargeant dynamiquement.

4. **Cr√©ation de l'objet `Definitions`**

```python
defs = Definitions(
    assets=[*trip_assets, *metric_assets]
)
```

Cette instruction combine les diff√©rents assets et les associe √† `Definitions`. Cet objet est essentiel, car Dagster recherche automatiquement un `Definitions` dans `__init__.py` lorsqu'on ex√©cute `dagster dev`.

### Pourquoi est-ce important ?

- `Definitions` permet √† Dagster de charger et de reconna√Ætre les assets du projet.
- Lorsqu'un projet Dagster grandit, il est n√©cessaire de **mettre √† jour `Definitions`** pour y inclure de nouveaux assets, ressources ou capteurs.
- En isolant chaque projet via une **code location**, Dagster permet une meilleure gestion et modularit√© des assets.

üöÄ **√Ä retenir** : `Definitions` est le point central permettant √† Dagster de comprendre et d'ex√©cuter les assets de votre projet. Toute modification dans la structure des assets doit √™tre r√©percut√©e dans cet objet.

---

### Comprendre les code locations dans Dagster

Nous avons parl√© des `Definitions`, mais qu'en est-il des **code locations** ? Comment fonctionnent-elles avec les `Definitions` ?

Une **code location** est un regroupement de d√©finitions Dagster, telles que les assets, permettant d'organiser et d'ex√©cuter le code de mani√®re isol√©e. Une code location est compos√©e de :

- **Un module Python** contenant un objet `Definitions`.
- **Un environnement Python** capable de charger ce module.

#### Pourquoi les code locations sont-elles utiles ?

Dans l'univers du d√©veloppement logiciel, un **d√©ploiement** est le processus permettant de rendre une application accessible aux utilisateurs. Un d√©ploiement Dagster inclut tous les √©l√©ments n√©cessaires √† son ex√©cution : Python, les packages comme Pandas, l'interface Dagster UI, etc.

√Ä mesure que les organisations grandissent et que plusieurs √©quipes orchestrent leurs donn√©es, un unique d√©ploiement Dagster devient difficile √† g√©rer. Cela peut entra√Æner plusieurs probl√®mes :

- Une √©quipe d√©ployant un changement pourrait provoquer des **interruptions** pour une autre √©quipe.
- Deux mod√®les d'apprentissage automatique pourraient n√©cessiter **des versions diff√©rentes d'une m√™me biblioth√®que**.
- Une √©quipe pourrait √™tre contrainte d'utiliser une **ancienne version d'un orchestrateur** en raison de conflits de d√©pendances.
- Un trop grand nombre d'assets dans un seul environnement peut **rendre la navigation difficile**.

Plut√¥t que de multiplier les d√©ploiements (ce qui ajouterait de la complexit√© et des co√ªts en gestion des infrastructures), Dagster permet de **segmenter le code en plusieurs code locations**. Cela permet aux √©quipes d'isoler leur code tout en conservant une gestion centralis√©e des assets.

#### Exemple : La m√©taphore de la cuisine

Imaginons que vous ouvriez une **boulangerie** pour produire des cookies √† grande √©chelle. Vous pourriez diviser l'espace en plusieurs cuisines sp√©cialis√©es :

- Une **cuisine de test** pour exp√©rimenter de nouvelles recettes.
- Un **atelier d'emballage** pour conditionner les cookies.
- Une **zone de d√©coration** pour ajouter des finitions aux cookies.

Chaque zone fonctionne ind√©pendamment, ce qui √©vite que des incidents dans l'une n'affectent les autres (ex. un incendie dans la cuisine de test ne mettrait pas en p√©ril la production principale). **C'est exactement ce que permettent les code locations dans Dagster**.

#### Utilisation des code locations dans Dagster

Chaque **bo√Æte** sur le sch√©ma ci-dessous repr√©sente une code location. En s√©parant les code locations des services principaux de Dagster, le code des utilisateurs est isol√© et s√©curis√©. Cela signifie qu'un code location peut :

- Avoir **sa propre version de Python**.
- G√©rer **ses propres d√©pendances**.
- Ex√©cuter son code sans impacter les autres parties du projet.

#### Organisation des code locations

Les code locations peuvent √™tre utilis√©es pour segmenter le code en diff√©rentes cat√©gories :

- **Par √©quipe** (ex. marketing, produit, data science).
- **Par version de Python** (ex. un code legacy en Python 3.9 et un code plus r√©cent en Python 3.11).
- **Par version de d√©pendances** (ex. un mod√®le utilisant `PyTorch v1` et un autre `PyTorch v2`).

M√™me si ces code locations sont **isol√©es**, elles restent connect√©es via une m√™me **instance Dagster**. Un asset d√©fini dans une code location peut d√©pendre d'un asset d'une autre code location.

üöÄ **√Ä retenir** : Les code locations permettent d'√©viter les conflits entre √©quipes, de garantir l'√©volutivit√© du projet et d'offrir une meilleure gestion des d√©pendances sans avoir besoin de multiplier les d√©ploiements Dagster.

---

### Code locations dans Dagster UI

Dans cette section, nous allons explorer comment visualiser et g√©rer les **code locations** dans l'interface **Dagster UI**.

#### Visualiser les code locations

1. **Acc√©der aux code locations** :
   - Dans **Dagster UI**, cliquez sur **Deployments** dans la barre de navigation sup√©rieure.
   - Dans l'onglet **Code Locations**, vous verrez la liste des code locations disponibles, avec leur statut, la derni√®re mise √† jour et d'autres informations.
   
2. **Nom des code locations** :
   - Par d√©faut, une code location prend le nom du module charg√© par Dagster. Dans notre cas, la code location est nomm√©e **dagster_university**, car elle correspond au dossier principal du projet.

#### Gestion des erreurs de chargement des code locations

Si une erreur survient lors du chargement d'une code location, son statut appara√Ætra comme **Failed**.

1. **Identifier une erreur** :
   - Dans l'onglet **Code Locations**, une code location en √©chec affichera le statut **Failed**.
   - Cliquez sur **View Error** pour afficher les logs d'erreur et diagnostiquer le probl√®me.

#### Rechargement des d√©finitions

Lors de l'ajout ou de la modification de d√©finitions dans votre projet, il peut √™tre n√©cessaire de **rafra√Æchir la code location** pour que Dagster prenne en compte les nouvelles versions des fichiers.

Vous pouvez recharger les d√©finitions de deux mani√®res :

1. **Depuis l'onglet Deployments** :
   - Acc√©dez √† **Deployments > Code Locations**.
   - Cliquez sur le bouton **Reload** √† c√¥t√© de la code location concern√©e.

2. **Depuis la page Global Asset Lineage** :
   - Acc√©dez √† **Global Asset Lineage** dans Dagster UI.
   - Cliquez sur **Reload definitions** pour mettre √† jour toutes les d√©finitions du projet.

üöÄ **√Ä retenir** : Une code location centralise les d√©finitions Dagster et doit √™tre recharg√©e lorsqu‚Äôun asset est ajout√© ou modifi√© afin que Dagster prenne en compte les mises √† jour.

---

### Aper√ßu des Resources

Pr√©c√©demment, nous avons explor√© les assets, la mani√®re dont ils s'articulent pour former un pipeline de donn√©es et comment les ex√©cuter pour les mat√©rialiser.

L'objectif de Dagster est d'offrir une **vue unifi√©e** sur tous les pipelines de donn√©es d'une organisation. Pour y parvenir, Dagster doit √™tre capable d'interagir avec diff√©rents services et syst√®mes utilis√©s dans ces pipelines, comme le stockage cloud ou les entrep√¥ts de donn√©es. Dans cette section, nous allons voir comment accomplir cela en appliquant les meilleures pratiques d'ing√©nierie logicielle.

#### Le principe DRY (Don't Repeat Yourself)

Une **bonne pratique** essentielle en d√©veloppement logiciel est le principe **DRY (Don't Repeat Yourself)**. Ce principe recommande d'√©viter la redondance et d'√©crire un code qui soit **r√©utilisable** et **centralis√©** plut√¥t que dupliqu√© √† plusieurs endroits.

En appliquant ce principe √† Dagster, on r√©duit le nombre d'erreurs potentielles, on am√©liore la lisibilit√© du code et on facilite l'observabilit√© des processus et des assets d√©finis.

#### Tester dans l'environnement de d√©veloppement

√Ä mesure que les pipelines de donn√©es deviennent plus complexes, il devient essentiel de tester les modifications avant leur d√©ploiement en production. Une difficult√© en ing√©nierie des donn√©es est que le code et les environnements sont souvent **√©troitement coupl√©s**, rendant difficile la validation des changements sans impacter les syst√®mes en production.

Avec Dagster, il est possible de :

- **Utiliser une base de donn√©es locale** au lieu de la base de production.
- **Repr√©senter diff√©remment les connexions externes** selon l'environnement (d√©veloppement, test, production).
- **Cr√©er une r√©plique d‚Äôun environnement de production** en d√©veloppement afin de tester les modifications sans risques.

üöÄ **√Ä retenir** : En appliquant ces bonnes pratiques, vous rendez vos pipelines plus robustes, plus lisibles et plus faciles √† maintenir.

---

### Comprendre les resources dans Dagster

Les **resources** sont les outils et services externes utilis√©s pour cr√©er des assets dans Dagster.

#### M√©taphore des cookies üç™

Reprenons l'exemple de la fabrication de cookies. Pour r√©aliser une recette, plusieurs **ustensiles** et **appareils** sont n√©cessaires :

- Un **bol et une cuill√®re** pour m√©langer les ingr√©dients.
- Un **plateau de cuisson** pour d√©poser les cookies.
- Un **four** pour les cuire.

Ces √©l√©ments sont des **resources**, car ils sont utilis√©s **√† plusieurs reprises** dans le processus. Plut√¥t que de les dupliquer dans chaque √©tape, il est plus efficace de les **centraliser et r√©utiliser**.

#### Resources dans Dagster

Dans le contexte des pipelines de donn√©es, les resources peuvent inclure :

- Une **API** pour r√©cup√©rer des donn√©es.
- Un **stockage S3** pour sauvegarder des fichiers.
- Une **base de donn√©es** comme Snowflake ou BigQuery.
- Un **outil de visualisation** pour afficher les r√©sultats.

Les resources permettent de **standardiser et centraliser** les connexions avec ces services. L'interface **Dagster UI** facilite √©galement la visualisation et la gestion des resources utilis√©es dans le pipeline.

Dans la prochaine section, nous allons refactoriser notre projet pour g√©rer les connexions DuckDB via une resource d√©di√©e.

---

### Configuration d'une resource pour la base de donn√©es

Tout au long de ce module, nous avons utilis√© **DuckDB** pour stocker et transformer les donn√©es. Chaque asset n√©cessitant une connexion √† DuckDB contenait une ligne similaire √† celle-ci :

```python
conn = backoff(
    fn=duckdb.connect,
    retry_on=(RuntimeError, duckdb.IOException),
    kwargs={
        "database": os.getenv("DUCKDB_DATABASE"),
    },
    max_retries=10,
)
```

Cette approche peut devenir **fragile et source d'erreurs** √† mesure que le projet √©volue. Une meilleure pratique consiste √† **centraliser la gestion de cette connexion** via une **resource Dagster**.

#### D√©finition d'une resource

Lors de la cr√©ation du projet, un dossier `resources/` contenant un fichier `__init__.py` a √©t√© g√©n√©r√©. Nous allons y d√©finir une resource partag√©e pour g√©rer la connexion √† DuckDB.

Ajoutez le code suivant dans `resources/__init__.py` :

```python
from dagster_duckdb import DuckDBResource

database_resource = DuckDBResource(
    database="data/staging/data.duckdb"
)
```

Ce code importe la resource `DuckDBResource` de la biblioth√®que `dagster_duckdb`, puis cr√©e une instance **r√©utilisable** de cette resource.

#### Utilisation des variables d'environnement

Les variables d'environnement sont un moyen standardis√© de stocker des configurations sensibles (comme des mots de passe ou des chemins de connexion). Jusqu'ici, nous avons utilis√© `os.getenv` pour r√©cup√©rer ces variables dans le fichier `.env`.

Plut√¥t que d'**inscrire directement le chemin** de la base de donn√©es, nous allons utiliser **Dagster's EnvVar** pour le rendre plus dynamique. Modifiez `resources/__init__.py` comme suit :

```python
from dagster_duckdb import DuckDBResource
from dagster import EnvVar

database_resource = DuckDBResource(
    database=EnvVar("DUCKDB_DATABASE")  # Utilisation de la variable d'environnement
)
```

#### Diff√©rence entre `EnvVar` et `os.getenv`

- **`EnvVar`** r√©cup√®re la valeur **√† chaque ex√©cution**.
- **`os.getenv`** charge la valeur **une seule fois au d√©marrage**.

L'utilisation de **`EnvVar`** permet de changer la base de donn√©es utilis√©e **sans red√©marrer Dagster**.

#### Mise √† jour de `Definitions`

Les resources sont des **d√©finitions Dagster** et doivent √™tre ajout√©es √† l'objet `Definitions` pour √™tre utilisables.

Dans `dagster_university/__init__.py`, ajoutez :

```python
from .resources import database_resource
```

Puis, modifiez `Definitions` pour inclure la resource :

```python
defs = Definitions(
    assets=[*trip_assets, *metric_assets],
    resources={
        "database": database_resource,
    },
)
```

#### V√©rification dans Dagster UI

1. **Rendez-vous dans Dagster UI**.
2. **Cliquez sur "Deployment"**, puis **"Code locations"**.
3. **Rechargez les d√©finitions** en cliquant sur "Reload".
4. **Ouvrez la code location**, puis acc√©dez √† l'onglet **Resources**.
5. **Vous devriez voir une resource nomm√©e `database` list√©e**.

üöÄ **√Ä noter** : Pour l'instant, cette resource n'est pas encore utilis√©e par les assets. La prochaine section couvrira l'int√©gration de cette resource dans les assets existants.

---

### Utilisation des resources dans les assets

Maintenant que la resource est d√©finie, nous allons modifier l'asset `taxi_trips` pour l'utiliser.

#### Avant l'ajout de la resource

Actuellement, l'asset `taxi_trips` √©tablit une connexion √† DuckDB directement :

```python
@asset(
    deps=["taxi_trips_file"],
)
def taxi_trips() -> None:
    query = """
        create or replace table taxi_trips as (
          select
            VendorID as vendor_id,
            PULocationID as pickup_zone_id,
            DOLocationID as dropoff_zone_id,
            RatecodeID as rate_code_id,
            payment_type as payment_type,
            tpep_dropoff_datetime as dropoff_datetime,
            tpep_pickup_datetime as pickup_datetime,
            trip_distance as trip_distance,
            passenger_count as passenger_count,
            total_amount as total_amount
          from 'data/raw/taxi_trips_2023-03.parquet'
        );
    """

    conn = backoff(
        fn=duckdb.connect,
        retry_on=(RuntimeError, duckdb.IOException),
        kwargs={
            "database": os.getenv("DUCKDB_DATABASE"),
        },
        max_retries=10,
    )
    conn.execute(query)
```

#### Apr√®s l'ajout de la resource

Nous allons modifier `taxi_trips` pour utiliser la resource d√©finie pr√©c√©demment :

```python
@asset(
    deps=["taxi_trips_file"],
)
def taxi_trips(database: DuckDBResource) -> None:
    query = """
        create or replace table taxi_trips as (
          select
            VendorID as vendor_id,
            PULocationID as pickup_zone_id,
            DOLocationID as dropoff_zone_id,
            RatecodeID as rate_code_id,
            payment_type as payment_type,
            tpep_dropoff_datetime as dropoff_datetime,
            tpep_pickup_datetime as pickup_datetime,
            trip_distance as trip_distance,
            passenger_count as passenger_count,
            total_amount as total_amount
          from 'data/raw/taxi_trips_2023-03.parquet'
        );
    """

    with database.get_connection() as conn:
        conn.execute(query)
```

#### Changements effectu√©s :

1. **Importation de `DuckDBResource`** :
   ```python
   from dagster_duckdb import DuckDBResource
   ```
2. **Ajout d'un param√®tre `database: DuckDBResource`** dans la signature de la fonction.
3. **Remplacement de la connexion manuelle √† DuckDB** par :
   ```python
   with database.get_connection() as conn:
       conn.execute(query)
   ```

‚úÖ **Avantages** :
- Plus besoin d'utiliser `backoff`, la gestion des connexions est int√©gr√©e √† `DuckDBResource`.
- Plus de flexibilit√© pour changer la configuration de la base sans modifier chaque asset.

#### Avant de continuer

Avant de passer √† la suite, assurez-vous de :

- **Mettre √† jour `assets/trips.py` avec la nouvelle impl√©mentation de `taxi_trips`.**
- **Recharger les d√©finitions dans Dagster UI.**
- **Remat√©rialiser l'asset `taxi_trips`.**

üöÄ Une fois ces √©tapes termin√©es, la resource est correctement int√©gr√©e et pr√™te √† √™tre utilis√©e dans d'autres assets !

---

### Pratique: Refactorisation des assets pour utiliser les resources

Les assets suivants utilisent la base de donn√©es **DuckDB** :

- `taxi_zones`
- `manhattan_stats`
- `trips_by_week`

Mettez √† jour ces assets pour qu'ils utilisent la resource **DuckDBResource** au lieu d'une connexion directe √† la base de donn√©es.

---

### Analyse de l'utilisation des resources via Dagster UI

Maintenant que vos assets utilisent la resource `database`, vous pouvez analyser son utilisation dans Dagster UI.

#### Acc√©der √† l'onglet Resources

1. **Ouvrez Dagster UI**.
2. **Cliquez sur "Deployment"**, puis s√©lectionnez la code location **dagster_university**.
3. **Acc√©dez √† l'onglet "Resources"**.
4. Vous devriez voir que la colonne **Uses** affiche d√©sormais `4`, indiquant que quatre assets utilisent la resource `database`.
5. Dans la colonne **Name**, cliquez sur `database`.

#### Affichage des d√©tails d'une resource

- Cette page contient des informations d√©taill√©es sur la resource, y compris son type et sa configuration.

#### Visualisation de l'utilisation des resources

1. **Cliquez sur l'onglet "Uses"** pour voir quels assets utilisent cette resource.
2. Cette vue est essentielle pour comprendre quelles resources sont disponibles et comment elles sont exploit√©es.

#### Cas d'utilisation courants

- **Identifier les impacts potentiels d'une migration de base de donn√©es**.
- **Analyser l'augmentation des co√ªts de service** et retracer leur origine.

üöÄ **En utilisant cette interface, vous obtenez une vision claire de l'usage des resources dans vos pipelines Dagster.**

---

### Introduction aux Schedules dans Dagster

Jusqu'√† pr√©sent, vous avez construit un pipeline de donn√©es et l'avez mat√©rialis√© manuellement. Cependant, le r√¥le principal d'un orchestrateur est d'ex√©cuter ces processus sans intervention humaine.

Dans cette section, vous allez d√©couvrir la mani√®re la plus simple d'automatiser la mat√©rialisation r√©guli√®re des assets : **l'utilisation des schedules**.

---

### Comprendre les Schedules

Les **schedules** sont un moyen traditionnel de maintenir vos assets √† jour en d√©finissant un **intervalle de temps fixe** pour ex√©cuter un pipeline. Par exemple, un schedule peut √™tre d√©fini pour une ex√©cution **quotidienne, horaire, ou chaque lundi √† 9h00**.

#### Exemple de production automatis√©e üç™

Si votre boulangerie conna√Æt un grand succ√®s, vous devez cuire vos cookies **tous les jours √† 4h00 du matin** pour qu'ils soient frais lorsque les clients arrivent. Un **schedule Dagster** permettrait d‚Äôautomatiser ce processus sans intervention humaine.

Dans Dagster, un schedule permet d‚Äôexprimer **la fr√©quence d'ex√©cution d'un pipeline**, et chaque ex√©cution (tick) d√©clenche une mat√©rialisation des assets.

#### Anatomie d'un Schedule

Un schedule est compos√© de plusieurs √©l√©ments :

- **Un job** qui d√©finit quels assets doivent √™tre mat√©rialis√©s.
- **Une expression cron** qui d√©finit la fr√©quence d'ex√©cution.

Nous allons maintenant cr√©er un schedule qui met √† jour la plupart des assets **chaque mois**, en accord avec la publication des nouvelles donn√©es de taxi par la NYC Taxi & Limo Commission (TLC).

#### D√©finition des Jobs

Dans Dagster, **les jobs permettent de s√©lectionner une partie des assets** √† mat√©rialiser. Un **job** est utile lorsqu'on ne veut pas ex√©cuter **tous** les assets √† chaque ex√©cution.

Nous allons cr√©er un **job** qui exclut `trips_by_week` car cet asset doit √™tre mis √† jour plus fr√©quemment.

Dans `jobs/__init__.py`, ajoutez :

```python
from dagster import AssetSelection, define_asset_job

trips_by_week = AssetSelection.assets("trips_by_week")

trip_update_job = define_asset_job(
    name="trip_update_job",
    selection=AssetSelection.all() - trips_by_week
)
```

#### Expressions Cron

Les **expressions cron** sont le standard pour d√©finir des fr√©quences d'ex√©cution dans les orchestrateurs.

Exemple d‚Äôexpression cron :

```
15 5 * * 1-5
```

‚û°Ô∏è Cette expression signifie : **Tous les jours ouvr√©s (lundi-vendredi) √† 5h15 du matin**.

Des outils comme **Crontab Guru** permettent de tester des expressions cron avant de les utiliser. Toutefois, il est recommand√© de tester directement les schedules dans **Dagster UI** pour s‚Äôassurer du bon fonctionnement.

---

### Pratique : Cr√©ation d'un `weekly_update_job`

Pour mettre en pratique ce que vous avez appris, ajoutez un **job** dans `jobs/__init__.py` qui mat√©rialisera l'asset `trips_by_week`.

---

### Cr√©ation d'un Schedule

Maintenant que vous connaissez la structure d'un schedule, nous allons en cr√©er un √† l'aide de la classe `ScheduleDefinition`.

Ajoutez le code suivant dans `schedules/__init__.py` :

```python
from dagster import ScheduleDefinition
from ..jobs import trip_update_job

trip_update_schedule = ScheduleDefinition(
    job=trip_update_job,
    cron_schedule="0 0 5 * *",  # Tous les 5 du mois √† minuit
)
```

#### Explication du code :

- **Importation de `ScheduleDefinition`**.
- **Importation du job `trip_update_job`**.
- **Cr√©ation du schedule `trip_update_schedule`**, qui :
  - Est attach√© au job `trip_update_job`.
  - Utilise l'expression cron `0 0 5 * *`, qui ex√©cute le job **chaque 5 du mois √† minuit**.

üöÄ **Votre schedule est maintenant d√©fini !** Passez √† la suite pour l'ajouter √† Dagster UI.

### Pratique : Cr√©ation d'un `weekly_update_schedule`

Pour mettre en pratique ce que vous avez appris, ajoutez un **schedule** dans `schedules/__init__.py` qui :

- **Se nomme `weekly_update_schedule`**.
- **Mat√©rialise l'asset `trips_by_week`**.
- **S'ex√©cute chaque lundi √† minuit**.

---

### Mise √† jour de l'objet Definitions

Avant que les jobs et les schedules puissent √™tre utilis√©s, vous devez les ajouter √† l'objet `Definitions`.

#### Ajout des jobs dans `Definitions`

Revenons aux d√©finitions dans le fichier `__init__.py` √† la racine du projet. La premi√®re √©tape consiste √† ajouter les jobs pour que les schedules puissent les utiliser.

Ajoutez les imports suivants en haut du fichier :

```python
from .jobs import trip_update_job, weekly_update_job
```

Cela permet √† Dagster d'importer `trip_update_job` et `weekly_update_job` depuis `jobs/__init__.py`.

Sous la ligne `metric_assets = load_assets_from_modules([metrics])`, ajoutez :

```python
all_jobs = [trip_update_job, weekly_update_job]
```

Cela cr√©e une liste `all_jobs` contenant tous les jobs actuels, permettant d'en ajouter d'autres facilement √† l'avenir.

Dans l'objet `Definitions`, ajoutez l'argument `jobs` :

```python
jobs=all_jobs,
```

√Ä ce stade, le fichier `__init__.py` devrait ressembler √† ceci :

```python
from dagster import Definitions, load_assets_from_modules

from .assets import trips, metrics
from .resources import database_resource
from .jobs import trip_update_job, weekly_update_job

trip_assets = load_assets_from_modules([trips])
metric_assets = load_assets_from_modules([metrics])

all_jobs = [trip_update_job, weekly_update_job]

defs = Definitions(
    assets=[*trip_assets, *metric_assets],
    resources={
        "database": database_resource,
    },
    jobs=all_jobs,
)
```

#### Ajout des schedules dans `Definitions`

Maintenant que les jobs sont ajout√©s, nous allons ajouter les schedules √† `Definitions`.

Ajoutez les imports suivants en haut du fichier :

```python
from .schedules import trip_update_schedule, weekly_update_schedule
```

Sous la d√©finition de `all_jobs`, ajoutez :

```python
all_schedules = [trip_update_schedule, weekly_update_schedule]
```

Enfin, ajoutez l'argument `schedules` dans `Definitions` :

```python
schedules=all_schedules,
```

Le fichier `__init__.py` final devrait ressembler √† ceci :

```python
from dagster import Definitions, load_assets_from_modules

from .assets import trips, metrics
from .resources import database_resource
from .jobs import trip_update_job, weekly_update_job
from .schedules import trip_update_schedule, weekly_update_schedule

trip_assets = load_assets_from_modules([trips])
metric_assets = load_assets_from_modules([metrics])

all_jobs = [trip_update_job, weekly_update_job]
all_schedules = [trip_update_schedule, weekly_update_schedule]

defs = Definitions(
    assets=[*trip_assets, *metric_assets],
    resources={
        "database": database_resource,
    },
    jobs=all_jobs,
    schedules=all_schedules,
)
```
---

### Visualisation des Jobs et Schedules dans Dagster UI

Comme les autres d√©finitions Dagster, les jobs et schedules peuvent √™tre visualis√©s et g√©r√©s dans **Dagster UI**.

En plus de consulter et g√©rer ces √©l√©ments dans l'interface, l'ex√©cution de `dagster dev` lance √©galement le **dagster-daemon**. Ce processus surveille l'horloge pour ex√©cuter les jobs planifi√©s et activer les capteurs.

#### V√©rification des Jobs

1. **Rechargez les d√©finitions** dans Dagster UI avant de continuer.
2. Acc√©dez aux jobs en cliquant sur **Overview > Jobs**, ou via **Deployment > Code location > Jobs**.
3. La table affichera les informations suivantes :
   - **Nom** du job
   - **Schedules/Sensors** attach√©s au job
   - **Derni√®re ex√©cution**
   - **Historique des ex√©cutions**

En s√©lectionnant un job, vous pourrez voir son **graphe des assets**.

#### V√©rification des Schedules

1. Acc√©dez aux schedules en cliquant sur **Overview > Schedules**, ou via **Deployment > Code location > Schedules**.
2. La table affichera les d√©tails suivants :
   - **Nom du schedule**
   - **Fr√©quence d'ex√©cution** (ex. : mensuel, hebdomadaire...)
   - **Statut (activ√©/d√©sactiv√©)**
   - **Dernier tick et derni√®re ex√©cution**

#### Gestion des Schedules

- **Activation/D√©sactivation** : utilisez le bouton toggle √† c√¥t√© du nom du schedule.
- **Tester un schedule** : cliquez sur **Test Schedule** et s√©lectionnez un moment de simulation avant de cliquer sur **√âvaluer**.

üöÄ **Avec ces outils, vous avez maintenant une gestion compl√®te des jobs et schedules dans Dagster UI !**

---

### Introduction aux Partitions dans Dagster

Dans la le√ßon pr√©c√©dente, vous avez appris √† ex√©cuter vos pipelines r√©guli√®rement gr√¢ce aux **schedules**. 

Revenons √† notre analogie des cookies : si votre entreprise prosp√®re, vous commencerez √† prendre des **commandes en avance**. Pr√©parer chaque cookie d√®s qu‚Äôune commande arrive cr√©erait des probl√®mes, car :

- **Les commandes du jour sont plus urgentes** que celles pr√©vues pour la semaine prochaine.
- **Le volume de commandes fluctue** : certains jours, vous recevez 100 commandes, et d'autres jours, aucune.

Pour optimiser la production, vous **groupez** les commandes par **jour de retrait**, en ne pr√©parant que celles du jour concern√©. 

Ce concept de **partitionnement** s'applique √©galement aux **pipelines de donn√©es**. 

Dans cette le√ßon, vous apprendrez **pourquoi partitionner vos assets de donn√©es** et comment le faire avec Dagster en partitionnant les donn√©es des trajets de taxi.

---

### Partitions et Backfills dans Dagster

#### Qu'est-ce qu'une partition ?

Les partitions permettent de diviser les donn√©es en segments plus petits et plus faciles √† manipuler. Cette segmentation offre plusieurs avantages :

- **Efficacit√© des co√ªts** : Ne traiter que les donn√©es n√©cessaires, stocker les plus r√©centes dans un stockage rapide et les plus anciennes dans un stockage moins co√ªteux.
- **Acc√©l√©ration du calcul** : R√©partir un grand ensemble de donn√©es en parties plus petites am√©liore les performances des requ√™tes.
- **Scalabilit√©** : Distribuer les donn√©es sur plusieurs serveurs ou syst√®mes de stockage, ou ex√©cuter plusieurs partitions en parall√®le.
- **Traitement concurrent** : Ex√©cuter plusieurs partitions simultan√©ment pour acc√©l√©rer le traitement.
- **D√©bogage rapide** : Tester une partition individuelle avant d'ex√©cuter des analyses sur des plages de donn√©es plus larges.

Les partitions sont √† la fois un **mod√®le conceptuel** et une **repr√©sentation physique**. Dans Dagster, une seule d√©finition d‚Äôasset peut contenir plusieurs partitions. 

Par exemple, si nous stockons des commandes de cookies dans une base de donn√©es, elles peuvent √™tre toutes dans une m√™me table `orders`. En revanche, si elles sont stock√©es sur AWS S3 en fichiers parquet, il peut √™tre plus efficace de cr√©er un fichier parquet **par jour**.

En r√©sum√©, **les partitions permettent de manipuler des segments sp√©cifiques de donn√©es tout en laissant flexibles les m√©thodes de stockage et d'acc√®s**.

#### Qu'est-ce qu'un Backfill ?

Un **backfill** est le processus d'ex√©cution des partitions d'assets qui n'existent pas encore ou qui n√©cessitent une mise √† jour.

Les backfills sont couramment utilis√©s lors de la mise en place d'un pipeline pour la premi√®re fois, car les assets doivent √™tre mat√©rialis√©s pour refl√©ter les donn√©es historiques.

Autres cas d'utilisation :
- **Modification de la logique d'un asset** : Si l'algorithme de transformation des donn√©es change, un backfill permet de recalculer les valeurs historiques.
- **Rattrapage des partitions manquantes** : Si certaines partitions n‚Äôont pas √©t√© g√©n√©r√©es en raison d'une erreur, un backfill les r√©g√©n√®re.

üöÄ **Dans la section suivante, vous apprendrez √† partitionner un asset dans Dagster !**

---

### Cr√©ation d'une partition

Dans la section pr√©c√©dente, vous avez mis en place des **schedules** mensuels et hebdomadaires pour mat√©rialiser les assets. Vous allez maintenant modifier ces assets pour **partitionner les donn√©es des trajets de taxi** et ajouter une nouvelle partition √† chaque ex√©cution planifi√©e.

Heureusement, les donn√©es de trajets sont stock√©es sous forme de **fichiers parquet s√©par√©s par mois**, et NYC OpenData fournit des informations historiques remontant √† 2009. Cependant, pour optimiser l'utilisation des ressources, nous allons n'ing√©rer que les donn√©es **depuis le d√©but de 2023**.

#### D√©finition d'une partition

La premi√®re √©tape consiste √† d√©finir une **PartitionDefinition**. Dagster propose des partitions pr√©construites pour les donn√©es temporelles (**horaires, journali√®res, hebdomadaires, mensuelles**). 

Selon les bonnes pratiques de Dagster, les partitions doivent √™tre d√©finies dans le r√©pertoire `partitions/`. Pour ce projet, elles seront situ√©es dans `partitions/__init__.py`.

Votre projet Dagster contient √©galement un fichier `assets/constants.py`, qui d√©finit les variables `START_DATE` et `END_DATE` permettant de sp√©cifier la p√©riode des trajets √† ing√©rer.

Ajoutez le code suivant dans `partitions/__init__.py` :

```python
from dagster import MonthlyPartitionsDefinition
from ..assets import constants

start_date = constants.START_DATE
end_date = constants.END_DATE

monthly_partition = MonthlyPartitionsDefinition(
    start_date=start_date,
    end_date=end_date
)
```

üöÄ **Ici, nous cr√©ons une partition mensuelle `monthly_partition` en utilisant les dates de d√©but et de fin d√©finies dans `constants.py`.**

#### Nettoyage du stockage existant

Avant de continuer, il est recommand√© de **supprimer l'historique de mat√©rialisation** des assets existants. Cela est **n√©cessaire uniquement en environnement local**.

Ex√©cutez les commandes suivantes dans un terminal :

```bash
rm $DAGSTER_HOME/storage/taxi_trips_file $DAGSTER_HOME/storage/taxi_trips $DAGSTER_HOME/storage/trips_by_week
```

‚úÖ **Vous √™tes maintenant pr√™t √† impl√©menter la partition des assets !**

---

### Pratique : Cr√©ation d'une partition hebdomadaire

Pour mettre en pratique ce que vous avez appris, cr√©ez une **partition hebdomadaire** en utilisant `WeeklyPartitionsDefinition` de Dagster avec les m√™mes dates de d√©but et de fin.

Ajoutez la d√©finition de cette partition dans `partitions/__init__.py` en respectant la structure existante du projet.

üöÄ **Une fois la partition cr√©√©e, elle pourra √™tre utilis√©e pour organiser les donn√©es des trajets de taxi par semaine !**

---

### Ajout de partitions aux assets

Dans cette section, vous allez mettre √† jour les assets dans `assets/trips.py` pour utiliser les partitions.

Commen√ßons par `taxi_trips_file`, dont le code actuel est le suivant :

```python
@asset
def taxi_trips_file() -> None:
    """
      Les fichiers parquet bruts du dataset des trajets de taxi. Source : NYC Open Data.
    """
    month_to_fetch = '2023-03'
    raw_trips = requests.get(
        f"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{month_to_fetch}.parquet"
    )

    with open(constants.TAXI_TRIPS_TEMPLATE_FILE_PATH.format(month_to_fetch), "wb") as output_file:
        output_file.write(raw_trips.content)
```

Dans cet asset, `month_to_fetch` est d√©fini sur `2023-03` pour r√©cup√©rer les donn√©es des trajets de mars 2023. En utilisant `monthly_partition`, vous pouvez mettre √† jour l'asset pour r√©cup√©rer dynamiquement les donn√©es en fonction de la partition.

### Ajout de la partition √† l'asset :

1. **Importer `monthly_partition`** depuis le dossier partitions en ajoutant la ligne suivante en haut du fichier `assets/trips.py` :

    ```python
    from ..partitions import monthly_partition
    ```

2. **Modifier le d√©corateur `@asset`** pour ajouter le param√®tre `partitions_def` avec `monthly_partition` :

    ```python
    @asset(
        partitions_def=monthly_partition
    )
    ```

3. **Inclure l'argument `context` pour acc√©der aux m√©tadonn√©es**

    Dans Dagster, l'argument `context` fournit des m√©tadonn√©es sur la mat√©rialisation en cours. Ajoutez cet argument √† la fonction et activez l'annotation de type en important `AssetExecutionContext` :

    ```python
    from dagster import asset, AssetExecutionContext

    @asset(
        partitions_def=monthly_partition
    )
    def taxi_trips_file(context: AssetExecutionContext) -> None:
    ```

    **Remarque :** L'argument `context` n'est pas sp√©cifique aux partitions. Cependant, c'est la premi√®re fois que vous l'utilisez dans Dagster University. Il fournit des informations sur l'ex√©cution de l'asset, telles que la partition en cours de traitement, le job qui a d√©clench√© la mat√©rialisation ou les m√©tadonn√©es des ex√©cutions pr√©c√©dentes.

4. **Utiliser la cl√© de partition pour r√©cup√©rer dynamiquement les donn√©es du mois correspondant**

    ```python
    @asset(
        partitions_def=monthly_partition
    )
    def taxi_trips_file(context: AssetExecutionContext) -> None:
        partition_date_str = context.partition_key
    ```

5. **Adapter la cl√© de partition au format attendu par la source de donn√©es**

    Dans NYC OpenData, les fichiers de trajets de taxi sont structur√©s au format `YYYY-MM`. Cependant, `context.partition_key` fournit la date de la partition sous forme de cha√Æne `YYYY-MM-DD`. Il faut donc adapter ce format :

    ```python
    @asset(
        partitions_def=monthly_partition
    )
    def taxi_trips_file(context: AssetExecutionContext) -> None:
        partition_date_str = context.partition_key
        month_to_fetch = partition_date_str[:-3]
    ```

Apr√®s avoir suivi ces √©tapes, l'asset `taxi_trips_file` doit ressembler au code ci-dessous :

```python
from ..partitions import monthly_partition

@asset(
    partitions_def=monthly_partition
)
def taxi_trips_file(context: AssetExecutionContext) -> None:
  """
      Les fichiers parquet bruts du dataset des trajets de taxi. Source : NYC Open Data.
  """

  partition_date_str = context.partition_key
  month_to_fetch = partition_date_str[:-3]

  raw_trips = requests.get(
      f"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{month_to_fetch}.parquet"
  )

  with open(constants.TAXI_TRIPS_TEMPLATE_FILE_PATH.format(month_to_fetch), "wb") as output_file:
      output_file.write(raw_trips.content)
```

‚úÖ **D√©sormais, `taxi_trips_file` est partitionn√© et utilisera la partition correspondante √† chaque mat√©rialisation !**

---

### Exercice : Partitionner l'asset `taxi_trips`

Pour mettre en pratique ce que vous avez appris, partitionnez l'asset `taxi_trips` par mois en suivant ces directives :

- √âtant donn√© qu'un fichier parquet d'un mois donn√© peut contenir des donn√©es historiques en dehors du mois, il est recommand√© de partitionner **par le mois du fichier parquet** et non par le mois du trajet.
- √Ä chaque partition, ins√©rez les nouvelles donn√©es dans la table `taxi_trips`.
- Ajoutez une colonne `partition_date` pour repr√©senter de quelle partition provient chaque enregistrement.

### Suppression de la table existante

Avant d'appliquer ces modifications, vous devez supprimer l'ancienne table `taxi_trips` en raison de l'ajout de la nouvelle colonne `partition_date`. Pour cela, ex√©cutez la commande suivante dans un REPL Python ou un script temporaire :

```python
import duckdb
conn = duckdb.connect(database="data/staging/data.duckdb")
conn.execute("drop table trips;")
```

### Adaptation de la requ√™te SQL

√âtant donn√© que la table `taxi_trips` existera apr√®s la premi√®re mat√©rialisation d'une partition, la requ√™te SQL devra √™tre mise √† jour pour :

1. **Cr√©er la table `taxi_trips` si elle n'existe pas d√©j√†.**
2. **Supprimer les anciennes donn√©es correspondant √† `partition_date`** pour √©viter les doublons lors d'un backfill.
3. **Ins√©rer les nouveaux enregistrements du fichier parquet correspondant au mois de la partition.**

‚úÖ **Modifiez `taxi_trips` pour appliquer cette partition et validez votre impl√©mentation dans Dagster UI !**

---


### Cr√©ation d'un job planifi√© avec partitions

Dans la section pr√©c√©dente, vous avez cr√©√© le job `trip_update_job` qui met √† jour la plupart de vos assets. Ce job √©tait programm√© pour s'ex√©cuter le cinqui√®me jour de chaque mois √† minuit.

Maintenant que les assets pertinents sont partitionn√©s, la planification peut √™tre modifi√©e afin de ne r√©cup√©rer que les nouvelles donn√©es du dernier mois au lieu de rafra√Æchir l'int√©gralit√© des assets. C'est une **meilleure pratique** qui optimise les ressources et r√©duit le temps de calcul.

Actuellement, `trip_update_job` dans `jobs/__init__.py` doit ressembler √† ceci :

```python
trip_update_job = define_asset_job(
    name="trip_update_job",
    selection=AssetSelection.all() - AssetSelection.assets(["trips_by_week"]),
)
```

### Ajout de la partition au job

1. **Importer la partition mensuelle** depuis le fichier partitions :

    ```python
    from ..partitions import monthly_partition
    ```

2. **Ajouter le param√®tre `partitions_def`** dans le job pour qu'il utilise `monthly_partition` :

    ```python
    partitions_def=monthly_partition,
    ```

Apr√®s modifications, le job doit ressembler √† ceci :

```python
from dagster import define_asset_job, AssetSelection
from ..partitions import monthly_partition

trips_by_week = AssetSelection.assets("trips_by_week")

trip_update_job = define_asset_job(
    name="trip_update_job",
    partitions_def=monthly_partition, # partitions ajout√©es ici
    selection=AssetSelection.all() - trips_by_week
)
```
---

### Pratique : Partitionner l'asset `trips_by_week`

Pour mettre en pratique ce que vous avez appris, mettez √† jour `weekly_update_job` et `trips_by_week` pour qu'ils soient partitionn√©s de mani√®re hebdomadaire. Utilisez votre d√©finition `weekly_partition` existante provenant de l'exercice pr√©c√©dent.

### Instructions :

- Ajoutez `partitions_def=weekly_partition` √† l'asset `trips_by_week`.
- Assurez-vous que `weekly_update_job` utilise √©galement `weekly_partition`.
- V√©rifiez que la cl√© de partition est correctement int√©gr√©e dans la logique de r√©cup√©ration et d'insertion des donn√©es.
- Testez la mat√©rialisation de partitions distinctes dans Dagster UI.

‚úÖ **Une fois termin√©, v√©rifiez dans l'interface de Dagster que les partitions s'affichent correctement et que le traitement fonctionne comme pr√©vu.**

---

### Partitions et Backfills dans l'interface Dagster UI

Maintenant que vous avez cr√©√© vos partitions, utilis√© ces partitions dans les assets et mis √† jour les jobs avec des partitions pour cr√©er un schedule partitionn√©, examinons l'affichage dans l'interface Dagster UI. Si vous avez toujours `dagster dev` en cours d'ex√©cution, vous devrez **recharger les d√©finitions** pour assurer la visibilit√© des partitions.

### Visualisation et mat√©rialisation des assets avec partitions

#### √âtape 1

Naviguez vers **Assets > Asset lineage**. Comme vous le verrez dans le graphe des assets, les assets `taxi_trips` contiennent maintenant des informations de partition.

#### √âtape 2

En examinant de plus pr√®s l'asset `taxi_trips_file`, vous verrez trois partitions repr√©sentant les trois mois inclus dans la partition :

- ‚ö´ `0` indique que **z√©ro partitions ont √©t√© mat√©rialis√©es avec succ√®s**.
- O `All` indique que **toutes les partitions (trois) ne sont pas encore mat√©rialis√©es**.
- ‚ö†Ô∏è `0` repr√©sente qu'**aucune partition n'a √©chou√©**.

Cette information est utile pour obtenir un aper√ßu rapide de l'√©tat de votre asset.

#### √âtape 3

En cliquant sur **Materialize all**, une fen√™tre contextuelle s'affichera avec les informations de la partition.

Cela vous permet de choisir **quelles partitions mat√©rialiser** ou de **lancer un backfill** pour mat√©rialiser plusieurs partitions en une seule fois.

### Lancement d'un Backfill

#### √âtape 1

Pour d√©marrer le backfill, cliquez sur **Launch backfill** dans la fen√™tre contextuelle pr√©c√©dente. Par d√©faut, l'intervalle de dates couvrira toute la plage d√©finie.

Ensuite, allez dans **Overview > Backfills** pour voir les informations sur le backfill.

#### √âtape 2

Cliquez sur un backfill pour ouvrir sa page de d√©tails. Cette page affiche chaque asset en cours de mat√©rialisation, ainsi que son √©tat.

#### √âtape 3

Retournez sur la page **Global Asset Lineage** (**Assets > Asset lineage**).

Dans le graphe des assets, vous verrez que le statut des assets partitionn√©s et non partitionn√©s a √©t√© mis √† jour.

### Visualisation des d√©tails des partitions d'un asset

#### √âtape 1

Dans le graphe des assets, cliquez sur l'asset `taxi_trips` et ouvrez-le dans l'**Asset Catalog**. Chaque mois sera list√© comme une partition examinable.

#### √âtape 2

S√©lectionnez `2023-03-01` pour voir une partition sp√©cifique. Vous pourrez alors consulter **les informations sp√©cifiques √† cette partition**, y compris son lien avec les donn√©es sources (`taxi_trips_file`).

---

### Introduction aux capteurs dans Dagster

Pr√©c√©demment, vous avez √©crit un schedule pour ex√©cuter vos pipelines tous les mois. L'utilisation de schedules n'est qu'une des nombreuses mani√®res de d√©clencher la mat√©rialisation des assets dans Dagster.

Les ex√©cutions bas√©es sur des √©v√©nements sont courantes dans la r√©alit√©. Prenons l'exemple de notre boulangerie : nous recevons des livraisons d'ingr√©dients et devons les d√©placer en cuisine. De la m√™me mani√®re, les pipelines de donn√©es doivent parfois r√©agir √† des √©v√©nements externes.

Dans Dagster, vous pouvez utiliser **les capteurs (sensors)** pour automatiser vos pipelines et les rendre r√©actifs √† ces √©v√©nements.

---

### Qu'est-ce qu'un capteur ?

Les capteurs (**sensors**) sont un moyen de surveiller un √©v√©nement sp√©cifique et de d√©clencher des ex√©cutions en fonction de celui-ci. Ils fonctionnent en ex√©cutant p√©riodiquement une logique pour d√©terminer si une ex√©cution doit √™tre lanc√©e. Par d√©faut, les capteurs dans Dagster interrogent toutes les **30 secondes**.

Les capteurs sont particuli√®rement utiles pour **d√©clencher la mat√©rialisation d'un asset apr√®s qu'un √©v√©nement se soit produit**, par exemple :

- L'arriv√©e d'un nouveau fichier dans un emplacement sp√©cifique (ex: Amazon S3).
- La mat√©rialisation d'un autre asset.
- La lib√©ration d'un slot de travail dans un syst√®me externe.

### Contexte de cette section

Dans cette section, nous supposons un sc√©nario hypoth√©tique o√π les parties prenantes de vos rapports sur les trajets de taxi effectuent r√©guli√®rement des analyses exploratoires sur le nombre de trajets dans certains quartiers (ex: Manhattan ou Brooklyn) √† des plages horaires sp√©cifiques.

Elles cherchent √† r√©pondre √† des questions comme :

> *¬´ Comment les f√™tes de fin d'ann√©e affectent-elles le trafic aux heures de pointe √† Manhattan ? ¬ª*

Ce type de demandes r√©p√©titives mobilise une partie importante de votre temps. Pour automatiser ces analyses et permettre un **reporting en libre-service**, vous d√©cidez de mettre en place un **capteur Dagster**.

Vous avez con√ßu un formulaire d'intake qui g√©n√®re un fichier **JSON structur√©** d√©crivant la requ√™te et l'ins√®re dans le dossier `data/requests` de votre projet Dagster.

### Objectifs de l'automatisation avec un capteur

Nous allons maintenant configurer un capteur qui surveille l'apparition de nouvelles demandes et ex√©cute automatiquement les analyses associ√©es.

Lorsqu'un **nouveau fichier JSON** repr√©sentant une demande d'analyse arrive dans le r√©pertoire, **le capteur est d√©clench√© et mat√©rialise l'asset** correspondant. Si toutes les demandes ont d√©j√† √©t√© trait√©es, **aucune nouvelle mat√©rialisation ne sera effectu√©e**.

Pour r√©pondre √† ces besoins, nous allons :

1. **√âcrire une logique permettant de personnaliser la mat√©rialisation des assets en fonction des requ√™tes**.
2. **Cr√©er un nouvel asset qui g√©n√®re un rapport personnalis√© par requ√™te**.
3. **Ajouter un capteur pour surveiller les nouvelles requ√™tes et d√©clencher l'analyse automatiquement**.


---

### Configuration de la cr√©ation d'assets

La configuration de la cr√©ation d'assets n'est pas sp√©cifique aux capteurs, mais lorsqu'on mat√©rialise des assets, il peut √™tre n√©cessaire de personnaliser certains aspects de la logique en fonction du contexte d'ex√©cution. Par exemple, personnaliser un email en fonction du destinataire ou adapter une analyse en fonction d'une plage de dates.

Dans notre cas, nous voulons personnaliser la mat√©rialisation d'un asset en fonction du **quartier et de la plage de dates** sp√©cifi√©s par l'utilisateur dans sa requ√™te.

Ces configurations sont g√©n√©ralement ajout√©es **au niveau de l'ex√©cution** et peuvent √™tre utilis√©es dans les plannings et capteurs. De plus, elles peuvent √™tre configur√©es manuellement via l'interface utilisateur de Dagster lors du lancement d'une ex√©cution.

### Impl√©mentation de la configuration personnalis√©e

1. **Cr√©er un fichier `requests.py`** dans le dossier `assets`.
2. **Ajouter l'import suivant** en haut du fichier :

    ```python
    from dagster import Config
    ```

    Cet import permet d'utiliser `Config` comme classe de base pour la configuration personnalis√©e.

3. **D√©finir une nouvelle classe `AdhocRequestConfig`** qui contiendra les informations suivantes :
    - `filename` : Nom du fichier JSON contenant la requ√™te.
    - `borough` : Le quartier de New York √† analyser (**Manhattan, Brooklyn, Queens, Bronx, Staten Island**).
    - `start_date` : D√©but de la plage de dates demand√©e (**format YYYY-MM-DD**).
    - `end_date` : Fin de la plage de dates demand√©e (**format YYYY-MM-DD**).

Le fichier `requests.py` final devrait ressembler √† ceci :

```python
from dagster import Config

class AdhocRequestConfig(Config):
    filename: str
    borough: str
    start_date: str
    end_date: str
```

‚úÖ **Cette classe nous permettra de passer des configurations dynamiques aux mat√©rialisations d'assets en fonction des demandes sp√©cifiques des utilisateurs.**

---

### Cr√©ation d'un asset d√©clench√© par un capteur

Maintenant que vous avez d√©fini comment l'asset peut √™tre mat√©rialis√©, cr√©ons l'asset de rapport √† la demande.

1. **Ajoutez les imports suivants √† `requests.py` :**

    ```python
    from dagster import asset, Config
    from dagster_duckdb import DuckDBResource
    
    import matplotlib.pyplot as plt
    
    from . import constants
    ```

2. **Cr√©ez un nouvel asset nomm√© `adhoc_request` avec les arguments suivants :**

    - `config`, annot√© avec `AdhocRequestConfig`.
    - D√©pendances sur les assets `taxi_zones` et `taxi_trips`.
    - `database`, annot√© avec `DuckDBResource` pour pouvoir interroger DuckDB.

    ```python
    @asset(
        deps=["taxi_zones", "taxi_trips"]
    )
    def adhoc_request(config: AdhocRequestConfig, database: DuckDBResource) -> None:
    ```

3. **G√©n√©rez le nom du fichier de sortie** en utilisant un template fourni dans `assets/constants.py`, en supprimant l'extension `.json` :

    ```python
    file_path = constants.REQUEST_DESTINATION_TEMPLATE_FILE_PATH.format(config.filename.split('.')[0])
    ```

4. **√âcrivez une requ√™te SQL** qui :
    - Filtre les trajets qui n'ont pas commenc√© dans le borough sp√©cifi√©.
    - Agr√®ge les donn√©es par jour de la semaine et heure du jour.

    ```python
    query = f"""
      select
        date_part('hour', pickup_datetime) as hour_of_day,
        date_part('dayofweek', pickup_datetime) as day_of_week_num,
        case date_part('dayofweek', pickup_datetime)
          when 0 then 'Sunday'
          when 1 then 'Monday'
          when 2 then 'Tuesday'
          when 3 then 'Wednesday'
          when 4 then 'Thursday'
          when 5 then 'Friday'
          when 6 then 'Saturday'
        end as day_of_week,
        count(*) as num_trips
      from trips
      left join zones on trips.pickup_zone_id = zones.zone_id
      where pickup_datetime >= '{config.start_date}'
      and pickup_datetime < '{config.end_date}'
      and pickup_zone_id in (
        select zone_id
        from zones
        where borough = '{config.borough}'
      )
      group by 1, 2
      order by 1, 2 asc
    """
    ```

5. **Ex√©cutez la requ√™te dans DuckDB et stockez les r√©sultats dans un DataFrame :**

    ```python
    with database.get_connection() as conn:
        results = conn.execute(query).fetch_df()
    ```

6. **G√©n√©rez une visualisation** avec Matplotlib pour afficher le nombre de trajets en fonction de l'heure et du jour de la semaine :

    ```python
    fig, ax = plt.subplots(figsize=(10, 6))
    
    results_pivot = results.pivot(index="hour_of_day", columns="day_of_week", values="num_trips")
    results_pivot.plot(kind="bar", stacked=True, ax=ax, colormap="viridis")
    
    ax.set_title(f"Number of trips by hour of day in {config.borough}, from {config.start_date} to {config.end_date}")
    ax.set_xlabel("Hour of Day")
    ax.set_ylabel("Number of Trips")
    ax.legend(title="Day of Week")
    
    plt.xticks(rotation=45)
    plt.tight_layout()
    ```

7. **Enregistrez le graphique sous forme de fichier image** en utilisant `file_path` :

    ```python
    plt.savefig(file_path)
    plt.close(fig)
    ```

8. **V√©rifiez que votre fichier `requests.py` ressemble √† ceci :**

    ```python
    from dagster import Config, asset
    from dagster_duckdb import DuckDBResource
    
    import matplotlib.pyplot as plt
    
    from . import constants
    
    class AdhocRequestConfig(Config):
        filename: str
        borough: str
        start_date: str
        end_date: str
    
    @asset(
        deps=["taxi_zones", "taxi_trips"]
    )
    def adhoc_request(config: AdhocRequestConfig, database: DuckDBResource) -> None:
        """
          The response to an request made in the `requests` directory.
          See `requests/README.md` for more information.
        """
    
        file_path = constants.REQUEST_DESTINATION_TEMPLATE_FILE_PATH.format(config.filename.split('.')[0])
    
        query = f"""
            select
              date_part('hour', pickup_datetime) as hour_of_day,
              date_part('dayofweek', pickup_datetime) as day_of_week_num,
              case date_part('dayofweek', pickup_datetime)
                when 0 then 'Sunday'
                when 1 then 'Monday'
                when 2 then 'Tuesday'
                when 3 then 'Wednesday'
                when 4 then 'Thursday'
                when 5 then 'Friday'
                when 6 then 'Saturday'
              end as day_of_week,
              count(*) as num_trips
            from trips
            left join zones on trips.pickup_zone_id = zones.zone_id
            where pickup_datetime >= '{config.start_date}'
            and pickup_datetime < '{config.end_date}'
            and pickup_zone_id in (
              select zone_id
              from zones
              where borough = '{config.borough}'
            )
            group by 1, 2
            order by 1, 2 asc
        """
    
        with database.get_connection() as conn:
            results = conn.execute(query).fetch_df()
    
        fig, ax = plt.subplots(figsize=(10, 6))
        
        results_pivot = results.pivot(index="hour_of_day", columns="day_of_week", values="num_trips")
        results_pivot.plot(kind="bar", stacked=True, ax=ax, colormap="viridis")
        
        ax.set_title(f"Number of trips by hour of day in {config.borough}, from {config.start_date} to {config.end_date}")
        ax.set_xlabel("Hour of Day")
        ax.set_ylabel("Number of Trips")
        ax.legend(title="Day of Week")
        
        plt.xticks(rotation=45)
        plt.tight_layout()
        
        plt.savefig(file_path)
        plt.close(fig)
    ```
